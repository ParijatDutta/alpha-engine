name: Daily Trade Scraper
on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  scrape_and_update:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Essential permission
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install pandas requests lxml

      - name: Run Scraper
        run: python cron_scraper.py

      - name: Upload Data via API (Bypass Git Push)
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # 1. Get the current file's 'sha' (required for the API to update)
          SHA=$(gh api repos/${{ github.repository }}/contents/daily_trades.csv -q .sha || echo "none")

          # 2. Encode the new CSV data to Base64
          CONTENT=$(base64 -w 0 daily_trades.csv)

          # 3. Use the GitHub API to overwrite the file directly
          if [ "$SHA" == "none" ]; then
            # Create the file if it doesn't exist
            gh api --method PUT /repos/${{ github.repository }}/contents/daily_trades.csv \
              -f message="Auto-create trades" \
              -f content="$CONTENT"
          else
            # Update the file if it does exist
            gh api --method PUT /repos/${{ github.repository }}/contents/daily_trades.csv \
              -f message="Auto-update trades: $(date +'%Y-%m-%d')" \
              -f content="$CONTENT" \
              -f sha="$SHA"
          fi