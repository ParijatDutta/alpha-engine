name: Daily Trade Scraper
on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

permissions:
  contents: write
  actions: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.MY_PAT }}
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: pip install pandas requests lxml
        
      - name: Run Scraper
        run: python cron_scraper.py
        
      - name: Commit and Push
        run: |
          # 1. Setup identity
          git config --local user.name 'github-actions[bot]'
          git config --local user.email 'github-actions[bot]@users.noreply.github.com'
          
          # 2. Hard sync with the remote to minimize gaps
          git fetch origin main
          git reset --soft origin main
          
          # 3. Check for actual changes in the CSV
          if git diff --quiet daily_trades.csv; then
            echo "No data changes. Skipping."
            exit 0
          fi

          # 4. Commit the new data
          git add daily_trades.csv
          git commit -m "Auto-update trade data: $(date +'%Y-%m-%d')"
          
          # 5. FORCE push to override the "fetch first" error
          # This is safe here because we are only automating a data file.
          git push origin main --force