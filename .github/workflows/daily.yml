name: Daily Trade Scraper
on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

permissions:
  contents: write
  actions: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.MY_PAT }}
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: pip install pandas requests lxml
        
      - name: Run Scraper
        run: python cron_scraper.py
        
      - name: Commit and Push
        run: |
          git config --local user.name 'github-actions[bot]'
          git config --local user.email 'github-actions[bot]@users.noreply.github.com'
          
          # 1. Update local origin/main reference
          git fetch origin main
          
          # 2. Check for changes
          if git diff --quiet daily_trades.csv; then
            echo "No changes in daily_trades.csv. Skipping."
            exit 0
          fi

          # 3. Add and commit
          git add daily_trades.csv
          git commit -m "Auto-update trade data: $(date +'%Y-%m-%d')"
          
          # 4. Pull any new remote changes (like your .yml edits) and put your commit on top
          git pull --rebase origin main
          
          # 5. Push the unified history
          git push origin main